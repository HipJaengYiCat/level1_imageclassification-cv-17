
Epoch[1/20](20/472) || training loss 2.56 || training accuracy 7.19% || train_f1_score 0.12 || lr 1e-05
Epoch[1/20](40/472) || training loss 2.505 || training accuracy 13.59% || train_f1_score 0.19 || lr 1e-05
Epoch[1/20](60/472) || training loss 2.453 || training accuracy 20.94% || train_f1_score 0.18 || lr 1e-05
Epoch[1/20](80/472) || training loss 2.397 || training accuracy 28.59% || train_f1_score 0.21 || lr 1e-05
Epoch[1/20](100/472) || training loss 2.33 || training accuracy 38.75% || train_f1_score 0.25 || lr 1e-05
Epoch[1/20](120/472) || training loss 2.267 || training accuracy 44.06% || train_f1_score  0.3 || lr 1e-05
Epoch[1/20](140/472) || training loss 2.202 || training accuracy 47.19% || train_f1_score 0.33 || lr 1e-05
Epoch[1/20](160/472) || training loss 2.096 || training accuracy 53.44% || train_f1_score 0.36 || lr 1e-05
Epoch[1/20](180/472) || training loss 1.996 || training accuracy 56.56% || train_f1_score 0.37 || lr 1e-05
Epoch[1/20](200/472) || training loss 1.867 || training accuracy 59.38% || train_f1_score 0.39 || lr 1e-05
Epoch[1/20](220/472) || training loss 1.774 || training accuracy 60.78% || train_f1_score 0.41 || lr 1e-05
Epoch[1/20](240/472) || training loss 1.639 || training accuracy 64.53% || train_f1_score 0.43 || lr 1e-05
Epoch[1/20](260/472) || training loss 1.56 || training accuracy 62.50% || train_f1_score 0.42 || lr 1e-05
Epoch[1/20](280/472) || training loss 1.389 || training accuracy 65.47% || train_f1_score 0.44 || lr 1e-05
Epoch[1/20](300/472) || training loss 1.332 || training accuracy 65.94% || train_f1_score 0.46 || lr 1e-05
Epoch[1/20](320/472) || training loss 1.181 || training accuracy 64.22% || train_f1_score 0.48 || lr 1e-05
Epoch[1/20](340/472) || training loss 1.139 || training accuracy 64.38% || train_f1_score 0.48 || lr 1e-05
Epoch[1/20](360/472) || training loss 1.001 || training accuracy 69.69% || train_f1_score 0.49 || lr 1e-05
Epoch[1/20](380/472) || training loss 0.9688 || training accuracy 68.59% || train_f1_score  0.5 || lr 1e-05
Epoch[1/20](400/472) || training loss 0.9553 || training accuracy 67.19% || train_f1_score 0.51 || lr 1e-05
Epoch[1/20](420/472) || training loss 0.8634 || training accuracy 69.53% || train_f1_score 0.51 || lr 1e-05
Epoch[1/20](440/472) || training loss 0.7377 || training accuracy 73.59% || train_f1_score 0.52 || lr 1e-05
Epoch[1/20](460/472) || training loss 0.7256 || training accuracy 70.94% || train_f1_score 0.52 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 75.58%! saving the best model..
[Val] acc : 75.58%, loss: 0.52 || best acc : 75.58%, best loss: 0.52 || f1 score : 0.71
early stopping patience 0
Epoch[2/20](20/472) || training loss 0.6366 || training accuracy 73.44% || train_f1_score 0.57 || lr 1e-05
Epoch[2/20](40/472) || training loss 0.5862 || training accuracy 73.28% || train_f1_score 0.67 || lr 1e-05
Epoch[2/20](60/472) || training loss 0.5901 || training accuracy 74.38% || train_f1_score 0.69 || lr 1e-05
Epoch[2/20](80/472) || training loss 0.5464 || training accuracy 72.97% || train_f1_score 0.68 || lr 1e-05
Epoch[2/20](100/472) || training loss 0.5526 || training accuracy 72.50% || train_f1_score 0.68 || lr 1e-05
Epoch[2/20](120/472) || training loss 0.4808 || training accuracy 75.16% || train_f1_score  0.7 || lr 1e-05
Epoch[2/20](140/472) || training loss 0.5002 || training accuracy 73.44% || train_f1_score  0.7 || lr 1e-05
Epoch[2/20](160/472) || training loss 0.4217 || training accuracy 76.88% || train_f1_score  0.7 || lr 1e-05
Epoch[2/20](180/472) || training loss 0.4037 || training accuracy 77.19% || train_f1_score  0.7 || lr 1e-05
Epoch[2/20](200/472) || training loss 0.4022 || training accuracy 75.78% || train_f1_score 0.69 || lr 1e-05
Epoch[2/20](220/472) || training loss 0.4031 || training accuracy 76.09% || train_f1_score 0.69 || lr 1e-05
Epoch[2/20](240/472) || training loss 0.3507 || training accuracy 78.59% || train_f1_score 0.71 || lr 1e-05
Epoch[2/20](260/472) || training loss 0.3069 || training accuracy 78.12% || train_f1_score  0.7 || lr 1e-05
Epoch[2/20](280/472) || training loss 0.3588 || training accuracy 76.72% || train_f1_score 0.69 || lr 1e-05
Epoch[2/20](300/472) || training loss 0.3688 || training accuracy 74.38% || train_f1_score  0.7 || lr 1e-05
Epoch[2/20](320/472) || training loss 0.3524 || training accuracy 77.19% || train_f1_score  0.7 || lr 1e-05
Epoch[2/20](340/472) || training loss 0.3502 || training accuracy 75.16% || train_f1_score  0.7 || lr 1e-05
Epoch[2/20](360/472) || training loss 0.279 || training accuracy 79.06% || train_f1_score 0.71 || lr 1e-05
Epoch[2/20](380/472) || training loss 0.2746 || training accuracy 77.66% || train_f1_score 0.71 || lr 1e-05
Epoch[2/20](400/472) || training loss 0.2823 || training accuracy 77.19% || train_f1_score 0.72 || lr 1e-05
Epoch[2/20](420/472) || training loss 0.2341 || training accuracy 80.16% || train_f1_score 0.73 || lr 1e-05
Epoch[2/20](440/472) || training loss 0.2308 || training accuracy 80.00% || train_f1_score 0.73 || lr 1e-05
Epoch[2/20](460/472) || training loss 0.2663 || training accuracy 77.03% || train_f1_score 0.73 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 81.32%! saving the best model..
[Val] acc : 81.32%, loss: 0.17 || best acc : 81.32%, best loss: 0.17 || f1 score : 0.77
early stopping patience 0
Epoch[3/20](20/472) || training loss 0.2451 || training accuracy 81.56% || train_f1_score 0.83 || lr 1e-05
Epoch[3/20](40/472) || training loss 0.2552 || training accuracy 77.81% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](60/472) || training loss 0.2049 || training accuracy 80.00% || train_f1_score 0.77 || lr 1e-05
Epoch[3/20](80/472) || training loss 0.2272 || training accuracy 78.91% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](100/472) || training loss 0.1871 || training accuracy 81.88% || train_f1_score 0.79 || lr 1e-05
Epoch[3/20](120/472) || training loss 0.1779 || training accuracy 81.88% || train_f1_score 0.81 || lr 1e-05
Epoch[3/20](140/472) || training loss 0.2159 || training accuracy 78.44% || train_f1_score 0.79 || lr 1e-05
Epoch[3/20](160/472) || training loss 0.1912 || training accuracy 80.31% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](180/472) || training loss 0.2053 || training accuracy 80.47% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](200/472) || training loss 0.1536 || training accuracy 82.97% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](220/472) || training loss 0.1674 || training accuracy 81.56% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](240/472) || training loss 0.1964 || training accuracy 77.81% || train_f1_score 0.77 || lr 1e-05
Epoch[3/20](260/472) || training loss  0.2 || training accuracy 79.22% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](280/472) || training loss 0.1957 || training accuracy 79.84% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](300/472) || training loss 0.1717 || training accuracy 81.09% || train_f1_score 0.79 || lr 1e-05
Epoch[3/20](320/472) || training loss 0.1611 || training accuracy 81.72% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](340/472) || training loss 0.1876 || training accuracy 80.00% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](360/472) || training loss 0.1538 || training accuracy 83.59% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](380/472) || training loss 0.1623 || training accuracy 78.91% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](400/472) || training loss 0.1392 || training accuracy 82.34% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](420/472) || training loss 0.1254 || training accuracy 83.75% || train_f1_score 0.79 || lr 1e-05
Epoch[3/20](440/472) || training loss 0.1639 || training accuracy 80.47% || train_f1_score 0.78 || lr 1e-05
Epoch[3/20](460/472) || training loss 0.1453 || training accuracy 82.66% || train_f1_score 0.77 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 85.63%! saving the best model..
[Val] acc : 85.63%, loss: 0.09 || best acc : 85.63%, best loss: 0.09 || f1 score : 0.83
early stopping patience 0
Epoch[4/20](20/472) || training loss 0.1513 || training accuracy 81.09% || train_f1_score 0.81 || lr 1e-05
Epoch[4/20](40/472) || training loss 0.1233 || training accuracy 84.22% || train_f1_score 0.84 || lr 1e-05
Epoch[4/20](60/472) || training loss 0.1586 || training accuracy 80.94% || train_f1_score 0.82 || lr 1e-05
Epoch[4/20](80/472) || training loss 0.1213 || training accuracy 84.53% || train_f1_score 0.82 || lr 1e-05
Epoch[4/20](100/472) || training loss 0.0994 || training accuracy 85.16% || train_f1_score 0.82 || lr 1e-05
Epoch[4/20](120/472) || training loss 0.1199 || training accuracy 83.28% || train_f1_score 0.82 || lr 1e-05
Epoch[4/20](140/472) || training loss 0.1189 || training accuracy 84.22% || train_f1_score 0.83 || lr 1e-05
Epoch[4/20](160/472) || training loss 0.1186 || training accuracy 84.38% || train_f1_score 0.82 || lr 1e-05
Epoch[4/20](180/472) || training loss 0.1237 || training accuracy 83.44% || train_f1_score 0.82 || lr 1e-05
Epoch[4/20](200/472) || training loss 0.112 || training accuracy 84.53% || train_f1_score 0.83 || lr 1e-05
Epoch[4/20](220/472) || training loss 0.1051 || training accuracy 86.09% || train_f1_score 0.84 || lr 1e-05
Epoch[4/20](240/472) || training loss 0.1152 || training accuracy 84.38% || train_f1_score 0.84 || lr 1e-05
Epoch[4/20](260/472) || training loss 0.1073 || training accuracy 84.22% || train_f1_score 0.84 || lr 1e-05
Epoch[4/20](280/472) || training loss 0.1092 || training accuracy 84.84% || train_f1_score 0.84 || lr 1e-05
Epoch[4/20](300/472) || training loss 0.1084 || training accuracy 85.00% || train_f1_score 0.84 || lr 1e-05
Epoch[4/20](320/472) || training loss 0.1057 || training accuracy 84.06% || train_f1_score 0.84 || lr 1e-05
Epoch[4/20](340/472) || training loss 0.1105 || training accuracy 84.06% || train_f1_score 0.85 || lr 1e-05
Epoch[4/20](360/472) || training loss 0.09034 || training accuracy 85.31% || train_f1_score 0.84 || lr 1e-05
Epoch[4/20](380/472) || training loss 0.07486 || training accuracy 87.97% || train_f1_score 0.85 || lr 1e-05
Epoch[4/20](400/472) || training loss 0.1042 || training accuracy 85.00% || train_f1_score 0.85 || lr 1e-05
Epoch[4/20](420/472) || training loss 0.0839 || training accuracy 85.31% || train_f1_score 0.85 || lr 1e-05
Epoch[4/20](440/472) || training loss 0.08241 || training accuracy 86.88% || train_f1_score 0.85 || lr 1e-05
Epoch[4/20](460/472) || training loss  0.1 || training accuracy 85.47% || train_f1_score 0.84 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 87.67%! saving the best model..
[Val] acc : 87.67%, loss: 0.057 || best acc : 87.67%, best loss: 0.057 || f1 score : 0.86
early stopping patience 0
Epoch[5/20](20/472) || training loss 0.07588 || training accuracy 86.88% || train_f1_score 0.79 || lr 1e-05
Epoch[5/20](40/472) || training loss 0.1161 || training accuracy 84.22% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](60/472) || training loss 0.06144 || training accuracy 88.59% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](80/472) || training loss 0.07897 || training accuracy 86.09% || train_f1_score 0.85 || lr 1e-05
Epoch[5/20](100/472) || training loss 0.07217 || training accuracy 89.06% || train_f1_score 0.85 || lr 1e-05
Epoch[5/20](120/472) || training loss 0.0765 || training accuracy 86.56% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](140/472) || training loss 0.07583 || training accuracy 87.03% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](160/472) || training loss 0.06456 || training accuracy 87.50% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](180/472) || training loss 0.07706 || training accuracy 86.88% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](200/472) || training loss 0.08959 || training accuracy 85.78% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](220/472) || training loss 0.08209 || training accuracy 85.00% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](240/472) || training loss 0.07949 || training accuracy 86.56% || train_f1_score 0.85 || lr 1e-05
Epoch[5/20](260/472) || training loss 0.0639 || training accuracy 88.12% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](280/472) || training loss 0.07891 || training accuracy 86.25% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](300/472) || training loss 0.05893 || training accuracy 87.50% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](320/472) || training loss 0.08644 || training accuracy 85.31% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](340/472) || training loss 0.0621 || training accuracy 87.66% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](360/472) || training loss 0.08293 || training accuracy 85.78% || train_f1_score 0.86 || lr 1e-05
Epoch[5/20](380/472) || training loss 0.07334 || training accuracy 85.78% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](400/472) || training loss 0.05528 || training accuracy 88.44% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](420/472) || training loss 0.04531 || training accuracy 89.69% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](440/472) || training loss 0.06085 || training accuracy 87.34% || train_f1_score 0.87 || lr 1e-05
Epoch[5/20](460/472) || training loss 0.06351 || training accuracy 86.88% || train_f1_score 0.87 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 88.54%! saving the best model..
[Val] acc : 88.54%, loss: 0.038 || best acc : 88.54%, best loss: 0.038 || f1 score : 0.87
early stopping patience 0
Epoch[6/20](20/472) || training loss 0.04597 || training accuracy 87.50% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](40/472) || training loss 0.04938 || training accuracy 89.06% || train_f1_score 0.87 || lr 1e-05
Epoch[6/20](60/472) || training loss 0.06017 || training accuracy 87.97% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](80/472) || training loss 0.06402 || training accuracy 87.19% || train_f1_score 0.87 || lr 1e-05
Epoch[6/20](100/472) || training loss 0.05083 || training accuracy 88.75% || train_f1_score 0.86 || lr 1e-05
Epoch[6/20](120/472) || training loss 0.0518 || training accuracy 88.28% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](140/472) || training loss 0.04457 || training accuracy 89.22% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](160/472) || training loss 0.05048 || training accuracy 87.97% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](180/472) || training loss 0.0658 || training accuracy 85.94% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](200/472) || training loss 0.06593 || training accuracy 86.41% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](220/472) || training loss 0.06257 || training accuracy 86.88% || train_f1_score 0.84 || lr 1e-05
Epoch[6/20](240/472) || training loss 0.05567 || training accuracy 88.12% || train_f1_score 0.84 || lr 1e-05
Epoch[6/20](260/472) || training loss 0.05128 || training accuracy 87.50% || train_f1_score 0.84 || lr 1e-05
Epoch[6/20](280/472) || training loss 0.0476 || training accuracy 89.84% || train_f1_score 0.84 || lr 1e-05
Epoch[6/20](300/472) || training loss 0.06372 || training accuracy 88.28% || train_f1_score 0.84 || lr 1e-05
Epoch[6/20](320/472) || training loss 0.05255 || training accuracy 88.75% || train_f1_score 0.84 || lr 1e-05
Epoch[6/20](340/472) || training loss 0.0544 || training accuracy 86.25% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](360/472) || training loss 0.03554 || training accuracy 89.06% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](380/472) || training loss 0.04914 || training accuracy 88.59% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](400/472) || training loss 0.05701 || training accuracy 85.47% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](420/472) || training loss 0.03177 || training accuracy 90.31% || train_f1_score 0.85 || lr 1e-05
Epoch[6/20](440/472) || training loss 0.05839 || training accuracy 88.12% || train_f1_score 0.86 || lr 1e-05
Epoch[6/20](460/472) || training loss 0.04337 || training accuracy 89.53% || train_f1_score 0.86 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 89.71%! saving the best model..
[Val] acc : 89.71%, loss: 0.028 || best acc : 89.71%, best loss: 0.028 || f1 score : 0.88
early stopping patience 0
Epoch[7/20](20/472) || training loss 0.04518 || training accuracy 87.19% || train_f1_score 0.83 || lr 1e-05
Epoch[7/20](40/472) || training loss 0.04628 || training accuracy 89.06% || train_f1_score 0.85 || lr 1e-05
Epoch[7/20](60/472) || training loss 0.06719 || training accuracy 86.25% || train_f1_score 0.76 || lr 1e-05
Epoch[7/20](80/472) || training loss 0.03157 || training accuracy 90.16% || train_f1_score 0.79 || lr 1e-05
Epoch[7/20](100/472) || training loss 0.0331 || training accuracy 89.69% || train_f1_score 0.82 || lr 1e-05
Epoch[7/20](120/472) || training loss 0.02976 || training accuracy 90.00% || train_f1_score 0.83 || lr 1e-05
Epoch[7/20](140/472) || training loss 0.03861 || training accuracy 89.53% || train_f1_score 0.83 || lr 1e-05
Epoch[7/20](160/472) || training loss 0.0275 || training accuracy 90.94% || train_f1_score 0.84 || lr 1e-05
Epoch[7/20](180/472) || training loss 0.04453 || training accuracy 86.88% || train_f1_score 0.84 || lr 1e-05
Epoch[7/20](200/472) || training loss 0.04191 || training accuracy 88.28% || train_f1_score 0.85 || lr 1e-05
Epoch[7/20](220/472) || training loss 0.04151 || training accuracy 89.22% || train_f1_score 0.85 || lr 1e-05
Epoch[7/20](240/472) || training loss 0.04259 || training accuracy 88.28% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](260/472) || training loss 0.04073 || training accuracy 88.59% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](280/472) || training loss 0.04854 || training accuracy 87.19% || train_f1_score 0.85 || lr 1e-05
Epoch[7/20](300/472) || training loss 0.04013 || training accuracy 90.00% || train_f1_score 0.85 || lr 1e-05
Epoch[7/20](320/472) || training loss 0.04482 || training accuracy 88.44% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](340/472) || training loss 0.04143 || training accuracy 89.53% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](360/472) || training loss 0.03782 || training accuracy 88.44% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](380/472) || training loss 0.0418 || training accuracy 87.34% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](400/472) || training loss 0.03246 || training accuracy 88.12% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](420/472) || training loss 0.02987 || training accuracy 89.69% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](440/472) || training loss 0.03783 || training accuracy 89.06% || train_f1_score 0.86 || lr 1e-05
Epoch[7/20](460/472) || training loss 0.02185 || training accuracy 91.88% || train_f1_score 0.86 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 90.05%! saving the best model..
[Val] acc : 90.05%, loss: 0.021 || best acc : 90.05%, best loss: 0.021 || f1 score : 0.89
early stopping patience 0
Epoch[8/20](20/472) || training loss 0.025 || training accuracy 91.72% || train_f1_score 0.92 || lr 1e-05
Epoch[8/20](40/472) || training loss 0.03261 || training accuracy 89.22% || train_f1_score 0.88 || lr 1e-05
Epoch[8/20](60/472) || training loss 0.02601 || training accuracy 92.03% || train_f1_score  0.9 || lr 1e-05
Epoch[8/20](80/472) || training loss 0.03036 || training accuracy 89.69% || train_f1_score 0.87 || lr 1e-05
Epoch[8/20](100/472) || training loss 0.02808 || training accuracy 90.62% || train_f1_score 0.87 || lr 1e-05
Epoch[8/20](120/472) || training loss 0.03279 || training accuracy 88.12% || train_f1_score 0.87 || lr 1e-05
Epoch[8/20](140/472) || training loss 0.03102 || training accuracy 88.28% || train_f1_score 0.87 || lr 1e-05
Epoch[8/20](160/472) || training loss 0.03352 || training accuracy 89.06% || train_f1_score 0.87 || lr 1e-05
Epoch[8/20](180/472) || training loss 0.0295 || training accuracy 89.69% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](200/472) || training loss 0.02483 || training accuracy 89.38% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](220/472) || training loss 0.02678 || training accuracy 89.69% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](240/472) || training loss 0.04304 || training accuracy 88.91% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](260/472) || training loss 0.02968 || training accuracy 90.00% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](280/472) || training loss 0.036 || training accuracy 90.00% || train_f1_score 0.87 || lr 1e-05
Epoch[8/20](300/472) || training loss 0.03549 || training accuracy 89.69% || train_f1_score 0.87 || lr 1e-05
Epoch[8/20](320/472) || training loss 0.03062 || training accuracy 89.22% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](340/472) || training loss 0.04285 || training accuracy 88.59% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](360/472) || training loss 0.02654 || training accuracy 89.69% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](380/472) || training loss 0.03488 || training accuracy 89.38% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](400/472) || training loss 0.02412 || training accuracy 90.47% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](420/472) || training loss 0.0215 || training accuracy 90.62% || train_f1_score 0.86 || lr 1e-05
Epoch[8/20](440/472) || training loss 0.0282 || training accuracy 90.62% || train_f1_score 0.87 || lr 1e-05
Epoch[8/20](460/472) || training loss 0.02254 || training accuracy 91.25% || train_f1_score 0.88 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 90.37%! saving the best model..
[Val] acc : 90.37%, loss: 0.017 || best acc : 90.37%, best loss: 0.017 || f1 score : 0.89
early stopping patience 0
Epoch[9/20](20/472) || training loss 0.02301 || training accuracy 90.78% || train_f1_score 0.94 || lr 1e-05
Epoch[9/20](40/472) || training loss 0.02164 || training accuracy 92.03% || train_f1_score 0.91 || lr 1e-05
Epoch[9/20](60/472) || training loss 0.02123 || training accuracy 91.25% || train_f1_score 0.88 || lr 1e-05
Epoch[9/20](80/472) || training loss 0.02752 || training accuracy 90.47% || train_f1_score 0.91 || lr 1e-05
Epoch[9/20](100/472) || training loss 0.02057 || training accuracy 90.00% || train_f1_score 0.91 || lr 1e-05
Epoch[9/20](120/472) || training loss 0.0256 || training accuracy 91.41% || train_f1_score 0.91 || lr 1e-05
Epoch[9/20](140/472) || training loss 0.02245 || training accuracy 91.56% || train_f1_score 0.91 || lr 1e-05
Epoch[9/20](160/472) || training loss 0.02911 || training accuracy 90.47% || train_f1_score 0.91 || lr 1e-05
Epoch[9/20](180/472) || training loss 0.01698 || training accuracy 92.50% || train_f1_score 0.92 || lr 1e-05
Epoch[9/20](200/472) || training loss 0.02261 || training accuracy 92.34% || train_f1_score 0.92 || lr 1e-05
Epoch[9/20](220/472) || training loss 0.03021 || training accuracy 90.94% || train_f1_score 0.92 || lr 1e-05
Epoch[9/20](240/472) || training loss 0.02465 || training accuracy 92.66% || train_f1_score 0.93 || lr 1e-05
Epoch[9/20](260/472) || training loss 0.02399 || training accuracy 91.25% || train_f1_score 0.93 || lr 1e-05
Epoch[9/20](280/472) || training loss 0.03738 || training accuracy 87.03% || train_f1_score 0.93 || lr 1e-05
Epoch[9/20](300/472) || training loss 0.02605 || training accuracy 91.25% || train_f1_score 0.93 || lr 1e-05
Epoch[9/20](320/472) || training loss 0.01889 || training accuracy 91.25% || train_f1_score 0.93 || lr 1e-05
Epoch[9/20](340/472) || training loss 0.02195 || training accuracy 91.56% || train_f1_score 0.93 || lr 1e-05
Epoch[9/20](360/472) || training loss 0.02411 || training accuracy 91.09% || train_f1_score 0.93 || lr 1e-05
Epoch[9/20](380/472) || training loss 0.01637 || training accuracy 92.97% || train_f1_score 0.92 || lr 1e-05
Epoch[9/20](400/472) || training loss 0.02859 || training accuracy 89.38% || train_f1_score 0.92 || lr 1e-05
Epoch[9/20](420/472) || training loss 0.02026 || training accuracy 90.94% || train_f1_score 0.92 || lr 1e-05
Epoch[9/20](440/472) || training loss 0.01936 || training accuracy 92.50% || train_f1_score 0.92 || lr 1e-05
Epoch[9/20](460/472) || training loss 0.0161 || training accuracy 93.12% || train_f1_score 0.92 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 91.48%! saving the best model..
[Val] acc : 91.48%, loss: 0.013 || best acc : 91.48%, best loss: 0.013 || f1 score : 0.91
early stopping patience 0
Epoch[10/20](20/472) || training loss 0.02275 || training accuracy 91.88% || train_f1_score 0.94 || lr 1e-05
Epoch[10/20](40/472) || training loss 0.01776 || training accuracy 91.72% || train_f1_score 0.88 || lr 1e-05
Epoch[10/20](60/472) || training loss 0.02338 || training accuracy 89.38% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](80/472) || training loss 0.02033 || training accuracy 90.78% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](100/472) || training loss 0.0168 || training accuracy 91.72% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](120/472) || training loss 0.02017 || training accuracy 91.72% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](140/472) || training loss 0.02154 || training accuracy 92.50% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](160/472) || training loss 0.01801 || training accuracy 92.34% || train_f1_score 0.88 || lr 1e-05
Epoch[10/20](180/472) || training loss 0.01995 || training accuracy 92.66% || train_f1_score 0.86 || lr 1e-05
Epoch[10/20](200/472) || training loss 0.01908 || training accuracy 90.94% || train_f1_score 0.86 || lr 1e-05
Epoch[10/20](220/472) || training loss 0.01513 || training accuracy 92.66% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](240/472) || training loss 0.01785 || training accuracy 90.62% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](260/472) || training loss 0.02328 || training accuracy 91.25% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](280/472) || training loss 0.01271 || training accuracy 93.75% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](300/472) || training loss 0.02449 || training accuracy 90.00% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](320/472) || training loss 0.01761 || training accuracy 91.72% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](340/472) || training loss 0.01592 || training accuracy 92.81% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](360/472) || training loss 0.01444 || training accuracy 90.94% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](380/472) || training loss 0.01958 || training accuracy 92.81% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](400/472) || training loss 0.02144 || training accuracy 92.34% || train_f1_score 0.87 || lr 1e-05
Epoch[10/20](420/472) || training loss 0.01258 || training accuracy 94.22% || train_f1_score 0.88 || lr 1e-05
Epoch[10/20](440/472) || training loss 0.01358 || training accuracy 93.75% || train_f1_score 0.88 || lr 1e-05
Epoch[10/20](460/472) || training loss 0.01578 || training accuracy 92.50% || train_f1_score 0.88 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 92.22%! saving the best model..
[Val] acc : 92.22%, loss: 0.01 || best acc : 92.22%, best loss: 0.01 || f1 score : 0.92
early stopping patience 0
Epoch[11/20](20/472) || training loss 0.01452 || training accuracy 93.28% || train_f1_score 0.97 || lr 1e-05
Epoch[11/20](40/472) || training loss 0.01089 || training accuracy 94.69% || train_f1_score 0.95 || lr 1e-05
Epoch[11/20](60/472) || training loss 0.01819 || training accuracy 91.88% || train_f1_score 0.95 || lr 1e-05
Epoch[11/20](80/472) || training loss 0.008397 || training accuracy 94.06% || train_f1_score 0.93 || lr 1e-05
Epoch[11/20](100/472) || training loss 0.01881 || training accuracy 92.34% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](120/472) || training loss 0.01164 || training accuracy 92.66% || train_f1_score 0.91 || lr 1e-05
Epoch[11/20](140/472) || training loss 0.01331 || training accuracy 93.44% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](160/472) || training loss 0.01753 || training accuracy 92.19% || train_f1_score 0.93 || lr 1e-05
Epoch[11/20](180/472) || training loss 0.01247 || training accuracy 92.66% || train_f1_score 0.93 || lr 1e-05
Epoch[11/20](200/472) || training loss 0.01166 || training accuracy 92.50% || train_f1_score 0.91 || lr 1e-05
Epoch[11/20](220/472) || training loss 0.0131 || training accuracy 91.72% || train_f1_score 0.91 || lr 1e-05
Epoch[11/20](240/472) || training loss 0.01496 || training accuracy 91.25% || train_f1_score 0.91 || lr 1e-05
Epoch[11/20](260/472) || training loss 0.01154 || training accuracy 93.44% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](280/472) || training loss 0.0209 || training accuracy 91.09% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](300/472) || training loss 0.02349 || training accuracy 91.56% || train_f1_score 0.91 || lr 1e-05
Epoch[11/20](320/472) || training loss 0.02412 || training accuracy 90.62% || train_f1_score 0.91 || lr 1e-05
Epoch[11/20](340/472) || training loss 0.009746 || training accuracy 93.91% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](360/472) || training loss 0.009676 || training accuracy 93.91% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](380/472) || training loss 0.01142 || training accuracy 93.91% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](400/472) || training loss 0.01102 || training accuracy 93.12% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](420/472) || training loss 0.01748 || training accuracy 90.94% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](440/472) || training loss 0.01362 || training accuracy 92.97% || train_f1_score 0.92 || lr 1e-05
Epoch[11/20](460/472) || training loss 0.01254 || training accuracy 91.88% || train_f1_score 0.92 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 92.88%! saving the best model..
[Val] acc : 92.88%, loss: 0.0086 || best acc : 92.88%, best loss: 0.0086 || f1 score : 0.92
early stopping patience 0
Epoch[12/20](20/472) || training loss 0.009214 || training accuracy 93.59% || train_f1_score 0.87 || lr 1e-05
Epoch[12/20](40/472) || training loss 0.008895 || training accuracy 94.06% || train_f1_score 0.92 || lr 1e-05
Epoch[12/20](60/472) || training loss 0.008926 || training accuracy 94.84% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](80/472) || training loss 0.009145 || training accuracy 94.06% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](100/472) || training loss 0.01279 || training accuracy 92.50% || train_f1_score 0.93 || lr 1e-05
Epoch[12/20](120/472) || training loss 0.007955 || training accuracy 94.69% || train_f1_score 0.93 || lr 1e-05
Epoch[12/20](140/472) || training loss 0.009959 || training accuracy 92.34% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](160/472) || training loss 0.01355 || training accuracy 90.62% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](180/472) || training loss 0.009089 || training accuracy 94.06% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](200/472) || training loss 0.01108 || training accuracy 93.28% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](220/472) || training loss 0.008822 || training accuracy 94.69% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](240/472) || training loss 0.01236 || training accuracy 93.91% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](260/472) || training loss 0.01428 || training accuracy 92.34% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](280/472) || training loss 0.009295 || training accuracy 93.91% || train_f1_score 0.93 || lr 1e-05
Epoch[12/20](300/472) || training loss 0.005548 || training accuracy 96.41% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](320/472) || training loss 0.007942 || training accuracy 93.91% || train_f1_score 0.94 || lr 1e-05
Epoch[12/20](340/472) || training loss 0.01864 || training accuracy 90.94% || train_f1_score 0.93 || lr 1e-05
Epoch[12/20](360/472) || training loss 0.01134 || training accuracy 94.69% || train_f1_score 0.93 || lr 1e-05
Epoch[12/20](380/472) || training loss 0.0147 || training accuracy 92.81% || train_f1_score 0.93 || lr 1e-05
Epoch[12/20](400/472) || training loss 0.01265 || training accuracy 94.84% || train_f1_score 0.93 || lr 1e-05
Epoch[12/20](420/472) || training loss 0.01042 || training accuracy 92.97% || train_f1_score 0.92 || lr 1e-05
Epoch[12/20](440/472) || training loss 0.01205 || training accuracy 94.06% || train_f1_score 0.93 || lr 1e-05
Epoch[12/20](460/472) || training loss 0.007072 || training accuracy 95.16% || train_f1_score 0.93 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 93.52%! saving the best model..
[Val] acc : 93.52%, loss: 0.0074 || best acc : 93.52%, best loss: 0.0074 || f1 score : 0.93
early stopping patience 0
Epoch[13/20](20/472) || training loss 0.01102 || training accuracy 93.44% || train_f1_score  1.0 || lr 1e-05
Epoch[13/20](40/472) || training loss 0.0109 || training accuracy 93.75% || train_f1_score 0.98 || lr 1e-05
Epoch[13/20](60/472) || training loss 0.006705 || training accuracy 95.47% || train_f1_score 0.98 || lr 1e-05
Epoch[13/20](80/472) || training loss 0.005201 || training accuracy 96.41% || train_f1_score 0.97 || lr 1e-05
Epoch[13/20](100/472) || training loss 0.009623 || training accuracy 94.06% || train_f1_score 0.97 || lr 1e-05
Epoch[13/20](120/472) || training loss 0.01415 || training accuracy 94.38% || train_f1_score 0.96 || lr 1e-05
Epoch[13/20](140/472) || training loss 0.008207 || training accuracy 93.75% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](160/472) || training loss 0.01155 || training accuracy 92.34% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](180/472) || training loss 0.01019 || training accuracy 94.38% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](200/472) || training loss 0.009599 || training accuracy 93.91% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](220/472) || training loss 0.005399 || training accuracy 95.94% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](240/472) || training loss 0.009793 || training accuracy 93.91% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](260/472) || training loss 0.00746 || training accuracy 95.78% || train_f1_score 0.96 || lr 1e-05
Epoch[13/20](280/472) || training loss 0.007257 || training accuracy 95.47% || train_f1_score 0.96 || lr 1e-05
Epoch[13/20](300/472) || training loss 0.007488 || training accuracy 94.84% || train_f1_score 0.96 || lr 1e-05
Epoch[13/20](320/472) || training loss 0.01023 || training accuracy 93.91% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](340/472) || training loss 0.007314 || training accuracy 95.47% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](360/472) || training loss 0.01527 || training accuracy 93.28% || train_f1_score 0.94 || lr 1e-05
Epoch[13/20](380/472) || training loss 0.009254 || training accuracy 95.00% || train_f1_score 0.94 || lr 1e-05
Epoch[13/20](400/472) || training loss 0.01031 || training accuracy 95.00% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](420/472) || training loss 0.00666 || training accuracy 95.00% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](440/472) || training loss 0.0114 || training accuracy 93.28% || train_f1_score 0.95 || lr 1e-05
Epoch[13/20](460/472) || training loss 0.006857 || training accuracy 95.16% || train_f1_score 0.95 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 94.31%! saving the best model..
[Val] acc : 94.31%, loss: 0.0057 || best acc : 94.31%, best loss: 0.0057 || f1 score : 0.94
early stopping patience 0
Epoch[14/20](20/472) || training loss 0.01466 || training accuracy 93.44% || train_f1_score  1.0 || lr 1e-05
Epoch[14/20](40/472) || training loss 0.004735 || training accuracy 95.62% || train_f1_score 0.96 || lr 1e-05
Epoch[14/20](60/472) || training loss 0.007424 || training accuracy 94.53% || train_f1_score 0.96 || lr 1e-05
Epoch[14/20](80/472) || training loss 0.005406 || training accuracy 94.84% || train_f1_score 0.97 || lr 1e-05
Epoch[14/20](100/472) || training loss 0.004275 || training accuracy 95.47% || train_f1_score 0.96 || lr 1e-05
Epoch[14/20](120/472) || training loss 0.009602 || training accuracy 93.59% || train_f1_score 0.96 || lr 1e-05
Epoch[14/20](140/472) || training loss 0.006229 || training accuracy 94.69% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](160/472) || training loss 0.006943 || training accuracy 95.16% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](180/472) || training loss 0.007808 || training accuracy 95.47% || train_f1_score 0.94 || lr 1e-05
Epoch[14/20](200/472) || training loss 0.004025 || training accuracy 95.62% || train_f1_score 0.94 || lr 1e-05
Epoch[14/20](220/472) || training loss 0.005469 || training accuracy 94.69% || train_f1_score 0.94 || lr 1e-05
Epoch[14/20](240/472) || training loss 0.007169 || training accuracy 96.25% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](260/472) || training loss 0.00548 || training accuracy 95.62% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](280/472) || training loss 0.006929 || training accuracy 95.16% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](300/472) || training loss 0.009202 || training accuracy 94.53% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](320/472) || training loss 0.007523 || training accuracy 95.78% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](340/472) || training loss 0.006752 || training accuracy 95.47% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](360/472) || training loss 0.01475 || training accuracy 95.31% || train_f1_score 0.94 || lr 1e-05
Epoch[14/20](380/472) || training loss 0.007096 || training accuracy 95.16% || train_f1_score 0.94 || lr 1e-05
Epoch[14/20](400/472) || training loss 0.006819 || training accuracy 95.62% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](420/472) || training loss 0.004983 || training accuracy 94.69% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](440/472) || training loss 0.006979 || training accuracy 95.62% || train_f1_score 0.95 || lr 1e-05
Epoch[14/20](460/472) || training loss 0.006238 || training accuracy 94.22% || train_f1_score 0.95 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 94.58%! saving the best model..
[Val] acc : 94.58%, loss: 0.0049 || best acc : 94.58%, best loss: 0.0049 || f1 score : 0.95
early stopping patience 0
Epoch[15/20](20/472) || training loss 0.005085 || training accuracy 95.31% || train_f1_score 0.93 || lr 1e-05
Epoch[15/20](40/472) || training loss 0.003486 || training accuracy 97.81% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](60/472) || training loss 0.003712 || training accuracy 96.41% || train_f1_score 0.97 || lr 1e-05
Epoch[15/20](80/472) || training loss 0.005037 || training accuracy 95.78% || train_f1_score 0.96 || lr 1e-05
Epoch[15/20](100/472) || training loss 0.004498 || training accuracy 95.94% || train_f1_score 0.96 || lr 1e-05
Epoch[15/20](120/472) || training loss 0.005447 || training accuracy 95.00% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](140/472) || training loss 0.008999 || training accuracy 96.09% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](160/472) || training loss 0.00432 || training accuracy 96.41% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](180/472) || training loss 0.006416 || training accuracy 95.47% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](200/472) || training loss 0.009188 || training accuracy 94.84% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](220/472) || training loss 0.004515 || training accuracy 96.25% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](240/472) || training loss 0.004246 || training accuracy 95.16% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](260/472) || training loss 0.006549 || training accuracy 95.78% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](280/472) || training loss 0.006232 || training accuracy 95.16% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](300/472) || training loss 0.00687 || training accuracy 95.78% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](320/472) || training loss 0.003146 || training accuracy 95.94% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](340/472) || training loss 0.004537 || training accuracy 95.47% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](360/472) || training loss 0.005331 || training accuracy 95.47% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](380/472) || training loss 0.00651 || training accuracy 94.53% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](400/472) || training loss 0.009959 || training accuracy 94.53% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](420/472) || training loss 0.004919 || training accuracy 95.78% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](440/472) || training loss 0.002654 || training accuracy 97.03% || train_f1_score 0.95 || lr 1e-05
Epoch[15/20](460/472) || training loss 0.003733 || training accuracy 97.19% || train_f1_score 0.95 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 94.63%! saving the best model..
[Val] acc : 94.63%, loss: 0.0043 || best acc : 94.63%, best loss: 0.0043 || f1 score : 0.95
early stopping patience 0
Epoch[16/20](20/472) || training loss 0.006335 || training accuracy 95.62% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](40/472) || training loss 0.005427 || training accuracy 95.00% || train_f1_score 0.95 || lr 1e-05
Epoch[16/20](60/472) || training loss 0.003762 || training accuracy 96.88% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](80/472) || training loss 0.004398 || training accuracy 96.41% || train_f1_score 0.95 || lr 1e-05
Epoch[16/20](100/472) || training loss 0.004692 || training accuracy 96.41% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](120/472) || training loss 0.003275 || training accuracy 95.47% || train_f1_score 0.94 || lr 1e-05
Epoch[16/20](140/472) || training loss 0.002516 || training accuracy 97.34% || train_f1_score 0.94 || lr 1e-05
Epoch[16/20](160/472) || training loss 0.00492 || training accuracy 96.56% || train_f1_score 0.95 || lr 1e-05
Epoch[16/20](180/472) || training loss 0.003236 || training accuracy 96.88% || train_f1_score 0.95 || lr 1e-05
Epoch[16/20](200/472) || training loss 0.00395 || training accuracy 96.72% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](220/472) || training loss 0.003824 || training accuracy 95.47% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](240/472) || training loss 0.00234 || training accuracy 97.19% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](260/472) || training loss 0.00608 || training accuracy 96.56% || train_f1_score 0.97 || lr 1e-05
Epoch[16/20](280/472) || training loss 0.002611 || training accuracy 97.34% || train_f1_score 0.97 || lr 1e-05
Epoch[16/20](300/472) || training loss 0.005457 || training accuracy 96.56% || train_f1_score 0.97 || lr 1e-05
Epoch[16/20](320/472) || training loss 0.007341 || training accuracy 94.84% || train_f1_score 0.97 || lr 1e-05
Epoch[16/20](340/472) || training loss 0.004463 || training accuracy 96.41% || train_f1_score 0.97 || lr 1e-05
Epoch[16/20](360/472) || training loss 0.004295 || training accuracy 96.09% || train_f1_score 0.97 || lr 1e-05
Epoch[16/20](380/472) || training loss 0.001731 || training accuracy 97.81% || train_f1_score 0.97 || lr 1e-05
Epoch[16/20](400/472) || training loss 0.00569 || training accuracy 95.31% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](420/472) || training loss 0.002355 || training accuracy 96.72% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](440/472) || training loss 0.002962 || training accuracy 96.41% || train_f1_score 0.96 || lr 1e-05
Epoch[16/20](460/472) || training loss 0.003618 || training accuracy 97.66% || train_f1_score 0.96 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 95.11%! saving the best model..
[Val] acc : 95.11%, loss: 0.0036 || best acc : 95.11%, best loss: 0.0036 || f1 score : 0.95
early stopping patience 0
Epoch[17/20](20/472) || training loss 0.005217 || training accuracy 95.62% || train_f1_score  1.0 || lr 1e-05
Epoch[17/20](40/472) || training loss 0.002615 || training accuracy 97.03% || train_f1_score  1.0 || lr 1e-05
Epoch[17/20](60/472) || training loss 0.003919 || training accuracy 96.09% || train_f1_score 0.99 || lr 1e-05
Epoch[17/20](80/472) || training loss 0.003059 || training accuracy 96.25% || train_f1_score 0.97 || lr 1e-05
Epoch[17/20](100/472) || training loss 0.004879 || training accuracy 95.16% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](120/472) || training loss 0.002476 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[17/20](140/472) || training loss 0.002912 || training accuracy 96.41% || train_f1_score 0.97 || lr 1e-05
Epoch[17/20](160/472) || training loss 0.002729 || training accuracy 97.03% || train_f1_score 0.97 || lr 1e-05
Epoch[17/20](180/472) || training loss 0.001728 || training accuracy 97.34% || train_f1_score 0.97 || lr 1e-05
Epoch[17/20](200/472) || training loss 0.003396 || training accuracy 96.41% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](220/472) || training loss 0.002401 || training accuracy 96.88% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](240/472) || training loss 0.002137 || training accuracy 96.88% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](260/472) || training loss 0.002757 || training accuracy 97.34% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](280/472) || training loss 0.002843 || training accuracy 97.50% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](300/472) || training loss 0.002422 || training accuracy 97.50% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](320/472) || training loss 0.002805 || training accuracy 96.88% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](340/472) || training loss 0.004551 || training accuracy 96.09% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](360/472) || training loss 0.002447 || training accuracy 96.88% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](380/472) || training loss 0.002507 || training accuracy 96.56% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](400/472) || training loss 0.003218 || training accuracy 96.72% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](420/472) || training loss 0.001865 || training accuracy 97.34% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](440/472) || training loss 0.003012 || training accuracy 96.72% || train_f1_score 0.98 || lr 1e-05
Epoch[17/20](460/472) || training loss 0.003703 || training accuracy 96.72% || train_f1_score 0.98 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 95.40%! saving the best model..
[Val] acc : 95.40%, loss: 0.0033 || best acc : 95.40%, best loss: 0.0033 || f1 score : 0.95
early stopping patience 0
Epoch[18/20](20/472) || training loss 0.001962 || training accuracy 97.03% || train_f1_score  0.9 || lr 1e-05
Epoch[18/20](40/472) || training loss 0.001755 || training accuracy 97.81% || train_f1_score 0.95 || lr 1e-05
Epoch[18/20](60/472) || training loss 0.002734 || training accuracy 96.88% || train_f1_score 0.97 || lr 1e-05
Epoch[18/20](80/472) || training loss 0.001986 || training accuracy 97.03% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](100/472) || training loss 0.003027 || training accuracy 96.41% || train_f1_score 0.97 || lr 1e-05
Epoch[18/20](120/472) || training loss 0.0019 || training accuracy 97.34% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](140/472) || training loss 0.002505 || training accuracy 95.94% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](160/472) || training loss 0.003769 || training accuracy 96.56% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](180/472) || training loss 0.005362 || training accuracy 96.41% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](200/472) || training loss 0.001358 || training accuracy 97.97% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](220/472) || training loss 0.002802 || training accuracy 97.03% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](240/472) || training loss 0.003306 || training accuracy 96.72% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](260/472) || training loss 0.002067 || training accuracy 96.72% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](280/472) || training loss 0.003061 || training accuracy 96.09% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](300/472) || training loss 0.003186 || training accuracy 97.66% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](320/472) || training loss 0.003219 || training accuracy 97.66% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](340/472) || training loss 0.002758 || training accuracy 97.34% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](360/472) || training loss 0.003137 || training accuracy 97.03% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](380/472) || training loss 0.002897 || training accuracy 96.41% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](400/472) || training loss 0.004837 || training accuracy 95.62% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](420/472) || training loss 0.001759 || training accuracy 98.12% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](440/472) || training loss 0.003124 || training accuracy 97.81% || train_f1_score 0.98 || lr 1e-05
Epoch[18/20](460/472) || training loss 0.003882 || training accuracy 96.56% || train_f1_score 0.98 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 95.53%! saving the best model..
[Val] acc : 95.53%, loss: 0.0029 || best acc : 95.53%, best loss: 0.0029 || f1 score : 0.96
early stopping patience 0
Epoch[19/20](20/472) || training loss 0.002468 || training accuracy 97.50% || train_f1_score  1.0 || lr 1e-05
Epoch[19/20](40/472) || training loss 0.001901 || training accuracy 97.97% || train_f1_score  1.0 || lr 1e-05
Epoch[19/20](60/472) || training loss 0.003118 || training accuracy 97.50% || train_f1_score  1.0 || lr 1e-05
Epoch[19/20](80/472) || training loss 0.001619 || training accuracy 97.97% || train_f1_score 0.98 || lr 1e-05
Epoch[19/20](100/472) || training loss 0.001963 || training accuracy 97.03% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](120/472) || training loss 0.004033 || training accuracy 96.72% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](140/472) || training loss 0.001514 || training accuracy 97.81% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](160/472) || training loss 0.001331 || training accuracy 97.81% || train_f1_score 0.96 || lr 1e-05
Epoch[19/20](180/472) || training loss 0.002582 || training accuracy 97.50% || train_f1_score 0.96 || lr 1e-05
Epoch[19/20](200/472) || training loss 0.002477 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](220/472) || training loss 0.001929 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](240/472) || training loss 0.001399 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](260/472) || training loss 0.001087 || training accuracy 98.12% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](280/472) || training loss 0.001661 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](300/472) || training loss 0.001855 || training accuracy 97.34% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](320/472) || training loss 0.00217 || training accuracy 97.81% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](340/472) || training loss 0.002734 || training accuracy 96.41% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](360/472) || training loss 0.002954 || training accuracy 97.34% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](380/472) || training loss 0.001894 || training accuracy 97.34% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](400/472) || training loss 0.002778 || training accuracy 96.09% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](420/472) || training loss 0.002262 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](440/472) || training loss 0.003022 || training accuracy 96.88% || train_f1_score 0.97 || lr 1e-05
Epoch[19/20](460/472) || training loss 0.002544 || training accuracy 96.72% || train_f1_score 0.97 || lr 1e-05
Calculating validation results...
New best model for val accuracy : 96.53%! saving the best model..
[Val] acc : 96.53%, loss: 0.0022 || best acc : 96.53%, best loss: 0.0022 || f1 score : 0.97
early stopping patience 0
Epoch[20/20](20/472) || training loss 0.005929 || training accuracy 95.78% || train_f1_score 0.94 || lr 1e-05
Epoch[20/20](40/472) || training loss 0.002064 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](60/472) || training loss 0.001667 || training accuracy 97.66% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](80/472) || training loss 0.002042 || training accuracy 97.19% || train_f1_score 0.98 || lr 1e-05
Epoch[20/20](100/472) || training loss 0.001476 || training accuracy 97.50% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](120/472) || training loss 0.001184 || training accuracy 97.81% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](140/472) || training loss 0.002655 || training accuracy 97.50% || train_f1_score 0.98 || lr 1e-05
Epoch[20/20](160/472) || training loss 0.001208 || training accuracy 97.66% || train_f1_score 0.98 || lr 1e-05
Epoch[20/20](180/472) || training loss 0.002682 || training accuracy 97.50% || train_f1_score 0.98 || lr 1e-05
Epoch[20/20](200/472) || training loss 0.0006155 || training accuracy 98.91% || train_f1_score 0.98 || lr 1e-05
Epoch[20/20](220/472) || training loss 0.001428 || training accuracy 97.81% || train_f1_score 0.98 || lr 1e-05
Epoch[20/20](240/472) || training loss 0.003064 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](260/472) || training loss 0.001256 || training accuracy 98.12% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](280/472) || training loss 0.001348 || training accuracy 97.50% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](300/472) || training loss 0.002501 || training accuracy 96.56% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](320/472) || training loss 0.001325 || training accuracy 97.50% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](340/472) || training loss 0.002185 || training accuracy 96.88% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](360/472) || training loss 0.001127 || training accuracy 98.44% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](380/472) || training loss 0.001032 || training accuracy 99.22% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](400/472) || training loss 0.001956 || training accuracy 97.66% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](420/472) || training loss 0.001774 || training accuracy 97.19% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](440/472) || training loss 0.001394 || training accuracy 97.66% || train_f1_score 0.97 || lr 1e-05
Epoch[20/20](460/472) || training loss 0.001288 || training accuracy 98.12% || train_f1_score 0.97 || lr 1e-05
Calculating validation results...
[Val] acc : 96.16%, loss: 0.0022 || best acc : 96.53%, best loss: 0.0022 || f1 score : 0.96
early stopping patience 0
[[565   0   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  9 342  12   0   2   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0  13 122   0   0   1   0   0   1   0   0   0   0   0   0   0   0   0]
 [  0   0   0 690   5   0   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   1 771  12   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0  11 129   0   0   0   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0  98   0   0   0   0   0   1   0   0   0   0   0]
 [  0   1   0   0   0   0   2  66   8   0   1   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0  20   0   0   0   0   0   0   0   0   0]
 [  0   0   0   0   0   0   2   0   0 138   1   0   0   0   0   0   0   0]
 [  0   0   0   0   2   0   1   0   0   3 151   4   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   4  25   0   0   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0 128   1   0   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   3  62  12   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   8  23   0   0   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 132   4   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2 148  10]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   2  25]]